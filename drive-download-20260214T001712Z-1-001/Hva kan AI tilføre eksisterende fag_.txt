TEMA 1b: Hva kan AI tilføre eksisterende fag?
A. Standpunkt (1–2 setninger)
Teknologisk folkeparti vil bruke AI til å løfte kvaliteten i eksisterende fag ved å gi mer tilpasset læring, mer praksisnær trening og sterkere faglig metode – uten å senke kravene til forståelse og ansvar. AI skal være en “faglig forsterker” som gjør undervisning og vurdering mer etterprøvbar, inkluderende og relevant for arbeidslivet, slik oppgaven også ber oss utfordre dagens “AI = juks”-refleks.
Bouvet-intro-og-oppgaver

B. Hvorfor (kjerneargument, 5–8 punkter)
1) Mer læring per time, fordi feedback kan bli kontinuerlig – ikke sporadisk.I mange fag er den største flaskehalsen ikke motivasjon, men mangelen på rask og presis tilbakemelding. Når studentene får feedback først etter innlevering, har de ofte allerede etablert dårlige vaner. AI kan gi hyppigere og mer målrettet veiledning underveis: på utkast, resonnering, disposisjon, og på småfeil som ellers ikke blir oppdaget før sent. Dette er særlig kraftfullt i matematikk, statistikk og metode, der adaptiv oppgavetrening kan “møte” studenten på riktig nivå og forklare akkurat det leddet som svikter – uten å gi fasiten gratis. Nettopp derfor blir gevinsten sosialt viktig: den reduserer avstanden mellom de som har nettverk/privatlærer og de som ikke har det.
2) Bedre faglig metode, fordi AI kan brukes som “motspiller” som studentene må kontrollere.Den virkelige verdien av AI i fag er ikke at den kan skrive eller regne for oss, men at den kan gi forslag som tvinger frem metode: “Hvorfor er dette riktig?”, “hvilke antakelser ligger inne?”, “hva ville falsifisert det?”. Utdanningsdirektoratet peker på at når KI er lett tilgjengelig, blir det ekstra viktig å variere og kombinere vurderingsformer og basere vurdering på flere kilder, nettopp for å være trygg på at det er elevens kompetanse som vurderes. Overført til høyere utdanning betyr det samme prinsippet: AI skal ikke være en snarvei rundt læring, men en katalysator for mer verifikasjon, kildebruk, kontrollregning og faglig begrunnelse.
3) Mer praksisnær utdanning, fordi simulering gir flere trygge repetisjoner.I profesjonsfag er treningstid ofte dyr, knapp og risikofylt. AI kan gi flere realistiske øvingsrunder før studenten møter virkelige pasienter, elever, klienter eller kritiske systemer. I helse kan det være triage- og journal-simulering, i jus kan det være casebasert dokumentanalyse og klientdialog, i lærerutdanning kan det være krevende foreldresamtaler og klasseledelse, og i ingeniørfag kan det være risikovurdering og kvalitetssikring i prosjekter. Dette handler ikke om å “automatisere” profesjonen, men om å gi mer mengdetrening på resonnering og etikk, med læreren som faglig garantist.
4) Bedre skriving og bedre tenking, fordi AI kan avlaste form – mens vi skjerper krav til innhold.AI kan hjelpe med språk, struktur og klarhet, og dermed frigjøre tid til faglig substans: analyse, argumentasjon og refleksjon. Men da må vi være tydelige på hva som vurderes: faglige valg, sammenheng i argumentasjon, presis bruk av begreper og etterprøvbar kildebruk. UHRs veiledende retningslinjer om fusk legger vekt på at institusjonene må jobbe forebyggende, ha tydelige regler, og at fagmiljøer bør ha klare retningslinjer for bruk av KI. Poenget er å gjøre det lett å være ærlig om verktøy – og vanskelig å få uttelling uten egen forståelse.
5) Økt inkludering og universell utforming, fordi flere kan delta på like vilkår.For studenter med dysleksi, språkvansker, konsentrasjonsutfordringer eller funksjonsnedsettelser kan AI være forskjellen på å henge med og å falle av. Det kan være støtte til å forstå tekst, strukturere en oppgave, få begreper forklart på ulike måter, eller oversette/forenkle uten at fagkravet senkes. Her er nøkkelen at vurderingen flyttes fra “hvem skriver penest” til “hvem kan faget best” – og at støtteverktøy blir en del av en rettferdig læringsarkitektur, ikke en privat fordel for de ressurssterke.
6) Mer relevans og bedre styring, fordi vi kan normalisere verktøybruk på en ansvarlig måte.NOKUT viser i Studiebarometeret at fire av fem studenter bruker KI i studiene, og at mange savner opplæring i riktig bruk. Når bruken er så utbredt, er den eneste realistiske strategien å gjøre den faglig: lære studentene å dokumentere, avgrense, kontrollere og reflektere. UNESCO understreker samtidig at utdanningssektoren må bygge kapasitet og sikre personvern og menneskelig kontroll når generativ AI tas i bruk.
7) Styrket tillit og mindre konflikt, fordi klare rammer slår bedre enn moralpanikk.Dagens debatt låser seg ofte i “forbud eller frislipp”. Teknologisk folkepartis linje er: tillat der det gir læring, begrens der læringsmålet krever det, og krev alltid sporbarhet når AI kan påvirke produktet. Som eksempel har Høgskulen på Vestlandet utviklet en trafikklysmodell (grønn/gul/rød) for KI-bruk, med tydelige dokumentasjonskrav og studentansvar. Det er denne typen rammeverk som gjør AI til et pedagogisk verktøy – ikke en evig disiplinærkrig.

C. Konkret politikk (6–10 tiltak)
Kort sikt (0–2 år)
1) Fagspesifikke AI-regler i hvert emne, skrevet som “slik bruker vi det her”.Mål: Fjerne uklarhet og gjøre AI-bruk rettferdig på tvers av kull og emner.Hvordan: Hvert emne skal beskrive konkret hva AI kan brukes til (idémyldring, struktur, språkstøtte, feilsøk, motargument), hva som ikke er lov, og hva som krever dokumentasjon. Vi bygger dette på prinsippet Utdanningsdirektoratet løfter frem: variasjon i vurdering og trygghet for at det er studentens kompetanse som vurderes.Ansvar: Institusjonene (fagansvarlige), med nasjonale minimumsprinsipper fra staten.
2) Innfør AI-feedback på utkast, men krev “revisjonsnotat” fra studenten.Mål: Mer læringsfremmende tilbakemelding uten at lærerens tidsbruk eksploderer.Hvordan: Studenten leverer et førsteutkast, får AI-basert tilbakemelding på struktur/logikk/mangler, og leverer et revidert utkast sammen med et kort notat: hva ble endret, hva ble avvist, og hvorfor. Dette gjør AI til en motor for forbedring – ikke en produsent av sluttprodukt.Ansvar: Institusjonene; staten støtter med kompetanseløft og felles retningslinjer.
3) Prioriter adaptiv trening i “flaskehalsfag” (matte, statistikk, metode).Mål: Redusere stryk og frafall og øke grunnleggende mestring.Hvordan: Innføre adaptiv oppgavetrening som krever forklaring av steg, ikke bare svar. Treningen kobles til korte muntlige “sjekkpunkter” i seminar/øving, slik at forståelse faktisk kontrolleres.Ansvar: Institusjonene; staten finansierer pilotering og evaluering.
Middels sikt (2–6 år)
4) Bygg AI-simulering inn i profesjonsfag som fast øvingsarena.Mål: Mer praksisnær mengdetrening før praksis/klinikk/virkelige oppdrag.Hvordan: Emnene etablerer scenario-økter der studentene øver på resonnering, etikk og kommunikasjon (for eksempel mini-OSCE-lignende opplegg i helse). Studentene vurderes på begrunnelse og håndtering av usikkerhet, ikke bare på “riktig svar”.Ansvar: Institusjonene i samarbeid med praksisfeltet; staten støtter utvikling.
5) Gjør “AI som motstander” til standard: verifikasjonsoppgaver med innebygde feil.Mål: Styrke kritisk metode og etterprøvbarhet.Hvordan: Studentene får et AI-generert forslag som inneholder plausible feil, manglende kilder eller svake antakelser, og må identifisere, forklare og rette det. Dette trener nøyaktig den kompetansen arbeidslivet trenger: kvalitetssikring og faglig dømmekraft.Ansvar: Institusjonene; nasjonal oppgavebank kan koordineres av staten.
6) Krev sporbarhet i laboratorie- og prosjektarbeid når AI påvirker analyse, kode eller konklusjon.Mål: Øke kvaliteten uten å svekke integritet.Hvordan: Studentene kan bruke AI til struktur/feilsøk/visualisering, men må levere en metode- og kontrollseksjon: hva AI foreslo, hva som ble testet, hva som ble forkastet, og hvilke kilder eller data som underbygger resultatet.Ansvar: Institusjonene; staten kan fastsette felles minimumskrav.
7) Gjør språk- og lesestøtte til universell utforming – uten å senke fagkrav.Mål: Flere skal kunne vise fagkompetanse, ikke bli stoppet av formbarrierer.Hvordan: AI kan brukes til språk og struktur, men vurdering vektlegger faglig innhold, metode og begrunnelse. Der det er nødvendig, suppleres skriftlig arbeid med muntlig/praktisk forsvar for å sikre at kompetansen faktisk er studentens.Ansvar: Institusjonene; staten sikrer finansiering og tilgang.
Lang sikt (6–15 år)
8) Etabler en nasjonal kunnskapsbank for kvalitetssikrede case, datasett og vurderingsrubrikker.Mål: Redusere avhengigheten av tilfeldige nett-kilder og heve faglig kvalitet.Hvordan: Bygge en offentlig, kvalitetssikret ressursbank med fagcase, anonymiserte datasett, eksempelbesvarelser, og rubrikker for AI-logg og verifikasjon. Dette gjør det enklere å bruke AI på en trygg, faglig måte.Ansvar: Staten og UH-sektoren i fellesskap.
9) Bruk AI til kvalitetsforbedring av studieprogram – men forby studentprofilering til sanksjonering.Mål: Bedre studiekvalitet uten overvåkningssamfunn.Hvordan: Bruke aggregerte data for å se hvor undervisningen kan forbedres, men sette klare grenser: ingen kommersiell profilering, ingen “risikoscore” på enkeltstudenter som brukes mot dem. Utdanningsdirektoratet understreker betydningen av sikre løsninger og personvernvurdering i skolesektoren; samme prinsipp skal gjelde i høyere utdanning.Ansvar: Staten setter rammene; institusjonene implementerer.

D. Risiko og sikkerhetsnett (4–6 punkter)
Den største risikoen er at AI blir en krykke som svekker grunnferdigheter. Derfor må fagene ha en bevisst progresjon: enkelte aktiviteter skal være AI-frie for å sikre at studentene faktisk kan skrive, regne, resonnere og anvende metode selv, mens andre aktiviteter kan være AI-assisterte – men da med krav om dokumentasjon og forsvar. Utdanningsdirektoratet anbefaler variasjon og flere vurderingskilder nettopp for å sikre at det er elevens (og overført: studentens) kompetanse som vurderes.
En annen risiko er feilinformasjon og falsk trygghet, fordi AI kan “se riktig ut” uten å være riktig. Sikkerhetsnettet er å gjøre verifikasjon til vurdert kompetanse: kildekrav, kontrollregning, test av antakelser og eksplisitt refleksjon over usikkerhet.
Vi må også ta på alvor risikoen for overvåkning og datainnsamling. Hvis AI-verktøy samler unødvendig data, undergraver det tillit. Utdanningsdirektoratet er tydelig på at skolen skal bruke sikre løsninger som er godkjent og personvernvurdert av skoleeier. Det samme prinsippet må gjelde i UH: institusjonene skal eie ansvaret for hvilke verktøy som brukes, og dataminimering skal være standard.
En fjerde risiko er ulikhet: forskjeller i tilgang og praksis mellom emner skaper urettferdighet. Derfor trenger vi minimumsstandarder, institusjonslisenser, og tydelige emnereglene. Trafikklysmodellen (grønn/gul/rød) er et konkret eksempel på hvordan dette kan gjøres med klare dokumentasjonskrav.
Til slutt kommer risikoen for integritetskonflikt: uklare regler gir flere fuskesaker og mer mistillit. UHRs retningslinjer vektlegger at institusjonene må informere tydelig og jobbe forebyggende, og at fagmiljøer bør ha klare KI-retningslinjer.

E. Måling og ansvarliggjøring (3–6 KPI-er)
For å vite om AI faktisk tilfører fagene noe, må vi måle mer enn “bruk”. Vi må måle læringsutbytte, for eksempel endring i strykprosent og gjennomføring i flaskehalsfag etter at adaptiv trening og AI-feedback er innført. Vi må måle kvalitet i faglig metode, gjennom rubrikker som vurderer verifikasjon, kildebruk og begrunnelse – ikke bare presentasjon. Vi må måle rettferdighet, ved å undersøke om studenter opplever reglene som klare og om tilgang er lik. Vi må måle tillit og personvern, gjennom antall avvik knyttet til AI-løsninger (mål: nær null) og studenters opplevelse av trygghet. Og vi må måle relevans, ved praksisfeltets vurdering av kandidatenes evne til å jobbe kvalitetssikret med AI i arbeidsflyten.

F. En sterk, kort “one-liner” til valgkamp (maks 20 ord)
AI skal gi mer praksis, bedre feedback og sterkere metode – ikke lavere krav.

G. Vanskeligste motargument + vårt beste svar (steelman, utdypet)
Motargument:“AI vil vanne ut eksisterende fag. Studentene kommer til å levere mer tekst og flere løsningsforslag, men lære mindre. Når vi ikke kan skille studentens arbeid fra maskinens bidrag, mister karakterer og grader troverdighet. I tillegg blir det urettferdig: de som er best til å bruke AI, får en urimelig fordel.”
Vårt svar:Dette er et sterkt motargument – og det blir sant dersom vi fortsetter å vurdere det AI er best til å etterligne: standardtekst, generiske forklaringer og overflatepresentasjon. Teknologisk folkepartis svar er derfor ikke å late som AI forsvinner, men å gjøre vurderingene mer robuste og mer faglige: Vi flytter tyngdepunktet fra “hva som leveres” til “hva som forstås, begrunnes og kan forsvares”.
Utdanningsdirektoratet peker på at KI gjør særlig vurdering av skriftlige oppgaver utfordrende, og anbefaler variasjon i opplæring og vurdering samt å basere vurdering på flere kilder for å være trygg på at det er elevens kompetanse som vurderes. Det er akkurat dette prinsippet vi løfter inn i fagutdanningene: større oppgaver skal bygges med sporbarhet (AI-bruk og metode synliggjøres), verifikasjon (kontroll av påstander, kilder og antakelser) og et kort forsvar (muntlig/praktisk) der studenten må kunne forklare, endre og feilsøke sin egen løsning. Da hjelper det ikke å være “flink til å få AI til å levere” hvis man ikke kan stå inne for resultatet.
Når det gjelder rettferdighet, er forbud ofte mer urettferdig enn regulert åpenhet. NOKUT viser at fire av fem studenter allerede bruker KI, og at mange savner opplæring. Et regime som later som om dette ikke skjer, belønner skjult bruk og straffer de ærlige. UHR understreker også behovet for tydelig informasjon og forebygging, og at fagmiljøer bør ha klare KI-retningslinjer. Med klare rammer, like tilgang til godkjente verktøy og krav om dokumentasjon, gjør vi konkurransen likere – og vurderingen mer presis.
Til slutt: Hvis frykten er at AI “tar over” faget, er løsningen å gjøre AI til en test av fagets kjerne. Profesjonell kompetanse er dømmekraft under usikkerhet: å kunne vurdere kvalitet, finne svakheter, velge metode og ta ansvar. Når AI blir en integrert del av læring og samtidig en integrert del av kontroll og begrunnelse, blir graden mer – ikke mindre – troverdig. Og når vi i tillegg følger UNESCOs linje om menneskesentrert bruk, personvern og kapasitetsbygging, sørger vi for at dette løftet ikke skjer naivt, men ansvarlig.


