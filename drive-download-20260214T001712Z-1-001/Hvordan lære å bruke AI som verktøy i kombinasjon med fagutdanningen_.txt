TEMA 1a: Hvordan lære å bruke AI som et verktøy i kombinasjon med yrkesfaglig utdanning?
A. Standpunkt (1–2 setninger)
Teknologisk folkeparti vil gjøre AI til en integrert del av yrkesfaglig utdanning – ikke som erstatning for håndverk og praksis, men som et faglig forsterkende verktøy som øker kvalitet, sikkerhet og mestring. Vi vil erstatte dagens defensive “AI = juks”-tilnærming med et nytt vurderingsregime der elevene må vise faglig dømmekraft, kritisk verifisering og ansvarlig AI-bruk gjennom sporbar dokumentasjon.
Bouvet-intro-og-oppgaver

B. Hvorfor (kjerneargument, i sammenhengende tekst)
For det første går digitaliseringen i yrkene raskere enn skolen klarer å oppdatere opplæringen. Når arbeidsplassen tar i bruk AI-støtte i planlegging, feilsøking, kvalitetssikring og dokumentasjon, blir det et gap mellom det vi lærer bort og det vi forventer at nyutdannede skal mestre. Utdanningsdirektoratet peker nettopp på at KI endrer rammene for opplæring og vurdering, og at skolen må utforske nye tilnærminger og sikre løsninger i tråd med læreplanene.
For det andre er AI en produktivitetsrevolusjon, og fagarbeideren må eie den – ikke bare tåle den. Hvis AI blir et “lederverktøy” som bare brukes til å kontrollere tempo, måle avvik og presse marginer, mister vi både kvalitet og arbeidslivsdemokrati. Når fagarbeideren derimot behersker verktøyet, kan hun stille bedre krav til sikkerhet, kvalitet og dokumentasjon, og hun kan overprøve dårlige anbefalinger. Det handler om maktbalanse: kompetanse er medbestemmelse i praksis.
For det tredje kan kvalitet og sikkerhet faktisk øke – men bare når AI brukes riktig og kritisk. En elektriker kan bruke AI til å gå gjennom koblingsskjema og foreslå risiko- og kontrollpunkter før arbeid starter, men må samtidig kunne forklare hvorfor et forslag er riktig eller feil ut fra normer, måleverdier og faglig praksis. En helsefagarbeider kan bruke AI-støtte til å strukturere journalnotat og fange opp uvanlige mønstre, men må kunne vurdere etikk, personvern, samtykke og profesjonsansvar. En tømrer kan bruke AI til å beregne materialsvinn og klimafotavtrykk, men må kunne kontrollregne, vurdere toleranser og velge løsninger som faktisk lar seg bygge. OECD peker på at innovative teknologier – inkludert AI og læringsanalyse – kan gi mer relevant opplæring, simulering og nye vurderingsformer i yrkesfag, hvis det gjøres strategisk og ansvarlig.
For det fjerde er demokrati og personvern ikke et “ekstra tema” for yrkesfag – det er kjernekompetanse. Yrkesfag jobber tett på folks hjem, helse, kjøretøy og bedrifters drift. Når AI-verktøy behandler tekst, bilder, sensordata eller kundedata, må elever lære dataminimering, taushetsplikt i digital form, og hva som er lov å dele i en chatbot og hva som aldri skal forlate virksomheten. Utdanningsdirektoratet understreker også behovet for sikre løsninger som skoleeier har vurdert, og at personvern må løftes frem i opplæringen.
For det femte er dette et inkluderingsprosjekt. Adaptiv oppgavetrening og en “AI-mentor” kan gi flere elever opplevelsen av å mestre teori, dokumentasjon og fagbegreper – uten at de må vente på at læreren rekker frem. Det kan bidra til lavere frafall, særlig der elevene møter en bratt overgang fra praktisk arbeid til skriftlige krav. Samtidig må vi unngå at AI blir en krykke som svekker grunnferdighetene. Derfor må opplæringen bygges som progresjon: først mestring uten støtte, deretter mestring med støtte – og til slutt profesjonell bruk med ansvar og dokumentasjon.
For det sjette er AI-kompetanse en forutsetning for grønn omstilling i praksis, ikke bare i festtaler. Yrkesfagene står i front for energieffektivisering, vedlikehold, materialvalg, sirkulære løsninger og redusert svinn. AI kan optimalisere – men bare hvis fagfolk kan vurdere konsekvensene og gjennomføre tiltakene på riktig måte.
Til slutt må vi erkjenne elefanten i rommet: AI finnes, og elevene bruker det uansett. Når vi later som verktøyet ikke eksisterer, skyver vi bruken ut i det skjulte – og da blir både læring, vurdering og etikk svakere. Utdanningsdirektoratet skriver at særlig vurdering av skriftlige oppgaver er utfordrende med lett tilgjengelig KI, og anbefaler variert vurderingspraksis og flere kilder for å sikre at det er elevens kompetanse som vurderes. Det er akkurat den retningen Teknologisk folkeparti vil gjøre til ny normal.
Bouvet-intro-og-oppgaver

C. Konkret politikk (grundig og implementerbar – i tekst)
I kort sikt (0–2 år) innfører vi en obligatorisk grunnmodul “AI i yrkesfag” som bygges inn i Vg1/Vg2. Modulen skal ikke være en løs teoridel, men en praktisk verktøyopplæring der eleven lærer tre ting samtidig: hva AI er og ikke er, hvordan AI brukes faglig (for eksempel til planlegging, dokumentasjon og kvalitetssikring), og hvordan man oppdager feil, skjevheter og usikkerhet i svarene. Elevene skal trene på konkrete arbeidsflyter, som “AI-a
Bouvet-intro-og-oppgaver
(med fremdrift, HMS og bestillingsliste), “AI-analyse av sikkerhetsrisiko” (med SJA/HMS-sjekkpunkter), og “AI-assistert rapport” der eleven må forbedre og verifisere alt som er foreslått. Gjennomføringen forankres i læreplanene og i Udirs råd om at skolen og læreren vurderer når KI er relevant, og at det skal være variasjon i vurdering.
Parallelt etablerer vi en trygg nasjonal AI-plattform for skoleeiere, med krav om personvernvurdering, dataminimering, tydelige bruksvilkår og sporbarhet. Poenget er ikke å låse skolen til én leverandør, men å sørge for at verktøyene som brukes, faktisk er vurdert og godkjent – slik Udir anbefaler når de sier at skolen bør bruke sikre løsninger som er godkjent og personvernvurdert av skoleeier. Plattformen skal støtte ulike nivåer av tilgang, slik at elever kan øve på generelle oppgaver uten å dele sensitiv informasjon, mens mer sensitive fag (for eksempel helse) bruker strengere løsninger og rutiner.
Den tredje satsingen i kort sikt er et kompetanseløft for yrkesfaglærere og instruktører. Vi vil finansiere betalt videreutdanning som er praksisnær: læreren skal komme tilbake med undervisningsopplegg, vurderingsrubrikker og case som passer eget utdanningsprogram. Dette bygger direkte på Udirs vektlegging av profesjonsfellesskap og en kultur for utprøving og evaluering, fordi AI endrer seg raskt og praksis må utvikles i fellesskap – ikke ved at hver lærer finner opp hjulet alene.
I middels sikt (2–6 år) skal AI integreres i selve fagkompetansen, ikke ligge som et “digitalt tillegg”. Det betyr at hvert utdanningsprogram får en tydelig AI-profil knyttet til arbeidsmåter som allerede finnes. I byggfag handler det om mengdeuttak, materialoptimalisering og klimaregnskap, der eleven må kunne forklare og justere modellens forslag og vise at byggbarhet og standarder er ivaretatt. I elektro handler det om feilsøking, dokumentasjon og risikoanalyse, der eleven må demonstrere manuell forståelse før AI brukes som støtte. I helse handler det om strukturert dokumentasjon, kommunikasjon og etisk refleksjon, der eleven lærer å bruke AI som “sekretær og sparringspartner” – men aldri som beslutningstaker. Denne innretningen støttes også av internasjonale anbefalinger om at teknologi i yrkesfag bør kobles til relevans, simulering og vurdering, og ikke bare “digital teori”.
Det viktigste grepet i middels sikt er et nytt vurderingsregime: AI skal være tillatt i de fleste vurderingssituasjoner, men bruken skal være synlig og etterprøvbar. Vi innfører derfor en obligatorisk AI-logg/AI-portfolio i sentrale fagoppgaver. Elevene skal levere (1) oppgaveproduktet, (2) en kort logg som viser hvordan AI ble brukt, (3) en “verifikasjonsdel” der eleven dokumenterer hva som er kontrollert, og (4) en refleksjon over hva AI ikke fikk til og hvorfor. I praksis betyr det at sensor ikke bare vurderer teksten eller resultatet, men elevens arbeidsprosess og faglige dømmekraft. Dette følger Udirs linje om at KI skaper usikkerhet om elevens egen innsats, og at det derfor blir ekstra viktig med variasjon og flere kilder i vurderingen.
Vi innfører også muntlige og praktiske kontrollpunkter som standard ved større innleveringer: korte, strukturerte samtaler der eleven må forklare valg, begrunne løsninger, peke på feil i et AI-forslag, og gjøre en “what if”-endring. En tømrer kan få spørsmålet: “Hvis leveransen endres fra 48x98 til 36x98, hva skjer med stivhet og festemønster – og hva foreslår du i praksis?” En mekaniker kan bli bedt om å forklare hvorfor en AI-diagnose kan være misvisende, og hvilke målinger som faktisk avgjør. Poenget er å gjøre vurdering robust uten å forby verktøyet.
Videre etablerer vi en AI-mentor i praksisperioder, men med tydelige rammer: verktøyet skal gi forslag, sjekklister og forklaringer, aldri overstyre instruktør, og alltid oppmuntre til verifisering. Vi vil bruke dette særlig for å støtte lærlinger i små lærebedrifter og i distrikter, der tilgang på spesialkompetanse kan være begrenset.
I lang sikt (6–15 år) oppretter vi en formalisert spesialisering, “digital fagarbeider”, der eleven kan bygge fordypning i AI-integrasjon, sensorteknologi, automatisering og dokumentasjonsstandarder oppå fagbrevet. Målet er ikke å gjøre alle til utviklere, men å gjøre flere til profesjonelle “superbrukere” som kan kombinere håndverk, sikkerhet og digital kvalitet. Dette svarer også på det bredere kompetansebehovet Norge står i: Kompetansebehovsutvalget, omtalt av regjeringen, peker på at Norge vil mangle digital kompetanse og at nye teknologier påvirker kompetansebehovene i arbeidsmarkedet.
Samtidig bygger vi offentlig AI-infrastruktur for utdanning for å redusere sårbarhet og avhengighet, og for å sikre at skole og lærebedrift har verktøy som tåler juridiske og etiske krav. Her må vi være realistiske: EU-regelverket legger strenge føringer for visse bruksområder i utdanning. AI Act klassifiserer blant annet flere systemer brukt i utdanning og yrkesopplæring som høy-risiko i bestemte anvendelser (for eksempel systemer som påvirker adgang/tilgang eller viktige beslutninger), og stiller krav til risikostyring, kvalitet og menneskelig tilsyn. Det betyr at vi må bygge styring og kvalitet inn i infrastrukturen fra start – ikke som “etterpå-lapp”.
Til slutt innfører vi en nasjonal sertifisering i ansvarlig AI-bruk for fagarbeidere. Den skal være praksisbasert: kunne dokumentere sikker arbeidsflyt, personvernforståelse, verifikasjonsrutiner og evne til å avdekke feil og skjevheter. Sertifiseringen blir et kvalitetsstempel i anbud og offentlige kontrakter, slik at ansvarlig bruk belønnes.

D. Risiko og sikkerhetsnett (i tekst)
Den største pedagogiske risikoen er at elever blir for avhengige av AI og mister grunnleggende ferdigheter. Derfor må opplæringen designes som en trapp: først “uten AI” for å sikre grunnkompetanse, så “med AI” for å lære arbeidsflyt og kritikk, og til slutt “profesjonell bruk” med dokumentasjon. I vurdering betyr det at enkelte delprøver kan være AI-frie, mens hovedoppgaver kan være AI-assisterte – nettopp for å måle både kjerneferdighet og verktøykompetanse.
Den største demokratiske risikoen er overvåkning og skjult profilering av elever, enten gjennom verktøy som samler data, eller gjennom analyse som rangerer elever uten åpenhet. Her må vi ha et tydelig prinsipp: ingen kommersiell profilering av barn og unge i skolen, og full åpenhet om hva som logges og hvorfor. Udir legger vekt på at sikre løsninger skal være godkjent og personvernvurdert av skoleeier; det må være minimumsstandard, ikke valgfag.
En tredje risiko er feilinformasjon og “hallusinasjoner” som kan gi farlige råd i praktiske fag. Derfor gjør vi verifisering til eksplisitt vurderingskriterium: Elevene skal trenes i å kontrollere mot standarder, målinger, tegninger, fagbøker og instruks – og i å dokumentere kontrollen. Når AI foreslår noe, skal elevens refleks være: “Hvordan vet jeg dette? Hva er usikkert? Hvilken test avgjør?”
En fjerde risiko er teknologisk klasseskille. Hvis noen skoler har gode verktøy og kompetente lærere mens andre blir stående igjen, øker ulikheten. Derfor finansierer staten både plattform, opplæring og minimumsutstyr, og vi måler jevnlig om tilbudet faktisk er likt på tvers.
En femte risiko er avhengighet av utenlandske leverandører og uklare vilkår. Her må Norge bygge en portefølje med flere alternativer og klare kontraktskrav, og samtidig investere i kompetanse slik at skolen ikke blir prisgitt “black box”-løsninger.

E. Måling og ansvarliggjøring (KPI-er)
Vi skal vite om politikken virker ved å måle både læring, kvalitet og tillit. Det betyr at vi følger utviklingen i frafall i yrkesfag over tid, men også ser på om elevene faktisk kan forklare og forsvare faglige valg i muntlige kontrollpunkter. Vi måler også kvaliteten på elevenes AI-logger (ikke mengden tekst, men sporbarhet, verifisering og refleksjon), antall personvernavvik knyttet til AI-verktøy, og arbeidsgiveres vurdering av nyutdannedes evne til å jobbe sikkert og effektivt med digital støtte. Udir peker på behovet for variasjon og flere vurderingskilder; våre KPI-er skal speile nettopp det: bredde i vurdering og etterprøvbar kompetanse, ikke “flink til å få chatbot til å skrive”.

F. One-liner (maks 20 ord)
Fremtidens fagarbeider mestrer både verktøykassa og algoritmene – med dømmekraft, ikke snarveier.

G. Vanskeligste motargument + vårt beste svar (utdypet)
Motargument (steelman): Å integrere AI i yrkesfag vil gi overfladisk kompetanse. Elevene lærer å “spørre pent” i stedet for å forstå. Verktøyet kan gjøre dem avhengige, og på sikt svekkes håndverket fordi maskinen tar over tenkingen.
Vårt beste svar: Dette motargumentet tar opp en reell fare – men det beskriver hva som skjer når AI enten forbys (så bruken blir skjult) eller slippes løs uten struktur (så verktøyet blir krykke). Teknologisk folkepartis løsning er å gjøre AI-bruk til en del av faglig ansvar, der eleven må bevise forståelse gjennom verifisering, praktisk utførelse og muntlig begrunnelse. Da blir AI ikke en snarvei, men en anledning til å trene kjerneferdigheter: å oppdage feil, vurdere risiko, velge mellom alternative løsninger og stå for beslutningen. Udir peker på at KI utfordrer særlig skriftlige vurderinger og at variasjon er nødvendig; vår modell gjør variasjonen systematisk og målbar.
I arbeidslivet blir man ikke vurdert på om man kan jobbe uten verktøy, men på om man leverer trygt og riktig med verktøy – og om man skjønner når verktøyet tar feil. Når vi vurderer “AI-kompetanse” riktig, vurderer vi i praksis profesjonsdømmekraft. Det er håndverkets kjerne, oppdatert til en ny tid.













A. Standpunkt (1–2 setninger)
Teknologisk folkeparti vil gjøre AI til en naturlig del av fagutdanningene – som et faglig hjelpemiddel på linje med statistikkverktøy, laboratorieutstyr og kliniske prosedyrer, ikke som en snarvei. Vi vil gå fra “AI = juks” til et nytt vurderingsregime der studentene vurderes på faglig dømmekraft, etterprøvbar arbeidsprosess og ansvarlig bruk av AI.
Bouvet-intro-og-oppgaver

B. Hvorfor (kjerneargument, skrevet som tekst)
1) Profesjonene er allerede AI-profesjoner – uten at utdanningen alltid er det. AI har i praksis blitt “bakgrunnsteknologi” i stadig flere yrker: Den dukker opp i prosjektering, journalføring, dokumentanalyse, diagnostikk, ressursplanlegging, risikovurdering og kvalitetssikring. Det betyr at fremtidens fagpersoner ikke bare må kunne sitt fag, men også kunne jobbe faglig med AI til stede i arbeidsflyten. Hvis utdanningen ikke tar dette inn i strukturerte former, lærer studentene det tilfeldig: noen får en fordel fordi de har riktige verktøy, riktig nettverk eller riktig kulturell kapital, mens andre blir hengende etter. Det er både urettferdig og ineffektivt – og gir dårligere kvalitet i profesjonsutøvelsen.
2) Riktig AI-bruk kan gi bedre kvalitet og sikkerhet – men bare dersom verifisering blir en del av faget. AI kan være briljant til å foreslå struktur, alternativer og forklaringer, men den kan også være feil med høy selvtillit. Det er spesielt farlig i fag der konsekvensene er store: feil beregning, feil tolkning av regelverk, feil prioritering i en klinisk situasjon. Derfor vil vi flytte tyngdepunktet i opplæringen fra “hva som leveres” til “hvordan det blir til”. Studentene må lære å bruke AI som en hypotese-generator og sparringspartner – og samtidig lære systematisk verifikasjon: kildesjekk, test, kontrollregning, sensitivitetssjekk, faglig vurdering opp mot standarder og etiske rammer. I praksis betyr det at “å være flink med AI” i vår modell er det samme som å være flink til metode, kvalitet og faglig ansvar.
3) Studentene bruker allerede AI – og mangelen på opplæring skaper et skjult klasseskille. Når en teknologi er utbredt, men regelverk og undervisningsopplegg er uklare, oppstår to parallelle verdener: en “offisiell” verden der AI er mistenkeliggjort, og en “uoffisiell” der studentene bruker den likevel – ofte uten å forstå risiko, begrensninger eller etikk. Dette gjør læring dårligere, fordi verktøyet brukes for å produsere, ikke for å lære. Samtidig gjør det vurdering urettferdig, fordi noen blir premiert for skjult effektivitet og andre straffet for å være åpne. Vi vil normalisere åpenhet, og gjøre kompetansen målbar – slik at likebehandling blir mulig.
4) Arbeidslivet trenger AI-kyndige fagfolk, ikke bare AI-brukere. Det holder ikke å kunne “få AI til å skrive”. Profesjonell AI-kompetanse betyr å kunne sette riktig problem, stille presise spørsmål, tolke svar kritisk, avdekke feilkilder og forstå når AI ikke skal brukes. Det betyr også å kunne dokumentere beslutninger, forklare metodevalg og ta ansvar for konsekvenser. I mange profesjoner er tillit selve valutaen: pasienten må stole på helsepersonell, klienten må stole på juristen, samfunnet må stole på ingeniørens beregninger. Derfor må AI-kompetanse bygges som en del av profesjonsetikken – ikke som et “digitalt tillegg”.
5) Personvern og demokrati må bygges inn i praksis – ellers mister vi kontroll over data og beslutninger. Fagutdanninger jobber tett på sensitive data: helseopplysninger, elevdata, klientinformasjon, bedriftsdata, sikkerhetskritiske systemer. AI kan gjøre dataflyt uklar: hva sendes hvor, hvem har tilgang, hvordan brukes det senere? Hvis studentene ikke lærer dette i praksis, risikerer vi både personvernbrudd og en glidning mot overvåkning og automatisert rangering. Teknologisk folkeparti vil derfor gjøre dataminimering, samtykke, anonymisering og sikker verktøybruk til en integrert del av læringsmålene – på samme måte som vi i dag lærer taushetsplikt, journalføring og dokumentasjonskrav.
6) Akademisk integritet kan ikke reddes med forbud alene – den må sikres gjennom bedre vurdering. Når vi behandler AI som et rent juks-problem, får vi et katt-og-mus-spill. Studentene får insentiv til å skjule bruken, undervisere får insentiv til å “jakte”, og begge parter mister tid og tillit. Det viktigste skiftet er derfor dette: Vi må gjøre det mulig å bruke AI åpent, men umulig å få uttelling uten egen forståelse. Det får vi ved å vurdere prosess, begrunnelse, verifikasjon og evnen til å forsvare og endre løsninger – ikke bare ved å vurdere sluttproduktet.
7) Et produktivitetsløft i kunnskapssamfunnet må komme fra dypere læring, ikke raskere tekst. AI kan spare tid på rutiner: førsteutkast, struktur, oppsummeringer, søk i store dokumentmengder. Men den samfunnsøkonomiske gevinsten kommer først når den frigjorte tiden faktisk brukes til mer trening på det mennesker skal være best på: faglig resonnering, etiske avveiinger, kritisk tenkning, kreativ problemløsning og profesjonell kommunikasjon. Derfor skal AI i utdanning brukes til å lære mer – ikke til å levere mer.

C. Konkret politikk (i tekst – mål, gjennomføring, ansvar)
Kort sikt (0–2 år)
1) “AI-førerkort” for alle studenter i fagutdanninger. Mål: Gi alle et felles minimumsnivå i ansvarlig og effektiv AI-bruk, slik at verken læring eller vurdering blir tilfeldig. Gjennomføring: Første studieår innfører alle fagutdanninger en obligatorisk modul der studentene trener på AI som metode: hvordan formulere faglige spørsmål, hvordan avdekke hallusinasjoner, hvordan sitere og redegjøre for bruk, hvordan håndtere opphavsrett, og hvordan beskytte sensitive data. Modulen skal være praktisk: eksempelvis en AI-assistert laboratorierapport der studentene må dokumentere kontrollpunkter, eller en AI-støttet metodeoppgave der de må vise at konklusjonen står på egne bein. Ansvar: Staten setter minimumsstandard (nasjonal ramme). Universiteter og høgskoler implementerer i studieprogram.
2) “AI-lab / AI-klinikk” i hvert studieprogram, én gang per semester. Mål: Gjøre AI-bruk konkret i fagets kjerneoppgaver og knytte det til profesjonens ansvar. Gjennomføring: Hvert program etablerer en fast læringsarena der studentene jobber med autentiske case og tydelige rammer. Ingeniørstudenter bruker AI til feilsøking i modeller og risikovurdering, men må dokumentere sikkerhetsmarginer og testmetode. Helsefagstudenter bruker AI til å strukturere journalutkast og trene på triage-scenarier, men må begrunne prioritering og dokumentere etiske hensyn. Lærerstudentene bruker AI til adaptiv oppgavetrening og tilrettelegging, men må vise didaktisk begrunnelse og inkludering. Ansvar: Institusjonene har ansvar for gjennomføring; praksisfeltet (sykehus, skoler, etater, bedrifter) medutvikler casene.
3) Sikker verktøytilgang som standard: institusjonsløsninger, ikke “hver student på egen konto”. Mål: Lik tilgang, lavere risiko, og tydelig ansvarslinje. Gjennomføring: Utdanningsinstitusjonene skal tilby godkjente AI-verktøy med databehandleravtaler, klare vilkår og sperrer mot deling av sensitiv informasjon. Der fagene krever skjermet behandling, skal det finnes alternativer med høyere sikkerhet (for eksempel lukkede eller lokale løsninger). Studentene skal ikke tvinges til å “ta risikoen selv” med private kontoer og uklare vilkår. Ansvar: Stat (krav/finansieringsmekanismer) og institusjoner (anskaffelse, drift og etterlevelse).
4) Kompetanseløft for undervisere og sensorer – meritterende og praksisnært. Mål: Sikre at vurdering og undervisning faktisk tåler AI, og at praksis blir likere på tvers av emner. Gjennomføring: Vi innfører betalt videreutdanning i “AI-pedagogikk og vurdering”, med fokus på oppgavedesign, muntlige forsvar, rubrikker for AI-logg, og personvern. Det skal utvikles felles ressurser og oppgavebanker som kan tilpasses lokalt, slik at kvalitet skalerer uten at hver underviser starter fra null. Ansvar: Institusjonene organiserer; staten støtter økonomisk og gjennom nasjonale fagmiljø.
Middels sikt (2–6 år)
5) Nytt vurderingsregime: AI kan være tillatt, men må være sporbar og etterprøvbar. Mål: Belønne læring og profesjonskompetanse, og gjøre det vanskelig å “skjule” manglende forståelse. Gjennomføring: I større oppgaver blir det normalisert at vurderingen består av tre deler: (1) produktet (rapport, løsning, plan), (2) prosessen (AI-logg og metode), og (3) et kort forsvar (muntlig, praktisk eller casebasert) der studenten må kunne forklare, endre og feilsøke sin egen løsning. I praksis betyr det: En student som bare kan levere en flott tekst, men ikke kan forklare valg, avdekke svakheter eller gjøre endringer, får ikke uttelling. Ansvar: Institusjoner og fagmiljø utformer; staten kan stille krav om minimumsprinsipper for integritet og etterprøvbarhet.
6) Trafikklysmodell i alle emner – med faglig begrunnelse, ikke vilkårlige forbud. Mål: Skape forutsigbarhet for studenter, og samtidig gi fagene nødvendig handlingsrom. Gjennomføring: Hvert emne merkes “grønn” (AI anbefalt), “gul” (AI tillatt med krav om logg/avgrensninger) eller “rød” (AI ikke tillatt i bestemte deler fordi læringsmålene krever det eller risikoen er høy). Det avgjørende er begrunnelsen: studentene skal forstå hvorfor en aktivitet er AI-fri, og hva de faktisk trener på. Ansvar: Institusjonene og fagansvarlige, innen nasjonale minimumskrav.
7) “Verifikasjonskompetanse” som eksplisitt læringsutbytte i alle fagutdanninger. Mål: Gjøre kontroll, testing og kvalitetssikring til en synlig og vurdert kjerneferdighet. Gjennomføring: Studentene får regelmessige oppgaver der de må: identifisere feil i et AI-forslag, forklare hva som er usikkert, og dokumentere hvordan de validerer med faglige kilder, data eller prosedyrer. Dette gjør AI til en treningsarena for kritisk metode, ikke en generator av “fasit”. Ansvar: Institusjonene og programråd.
8) Partnerskap med arbeidslivet om autentiske case – og klare etiske rammer. Mål: Sikre relevans og profesjonell standard, og samtidig beskytte data og mennesker. Gjennomføring: Vi etablerer casebanker med anonymiserte datasett, tydelige samtykker og rutiner for dataminimering. Praksisoppgaver skal inkludere krav om dokumentasjon av AI-bruk og refleksjon over etikk og risiko. Ansvar: Næringsliv/offentlig sektor bidrar med case; institusjonene gjør dem pedagogisk forsvarlige; staten sørger for standarder og støtte.
Lang sikt (6–15 år)
9) Nasjonalt senter for ansvarlig AI i fagutdanning og vurdering. Mål: Kontinuerlig kvalitetssikring, forskning på hva som virker, og felles standarder som beskytter tillit. Gjennomføring: Senteret utvikler vurderingsdesign, rubrikker for etterprøvbarhet, anbefalinger for datastyring og integritet, og støtter institusjoner i krevende anvendelser der AI kan gi høy risiko. Det skal også drive evaluering: gir AI-lab bedre læring? Reduserer det frafall? Øker det kvaliteten i praksis? Ansvar: Staten etablerer og finansierer; UH-sektoren leverer faglig innhold; praksisfeltet definerer profesjonskrav.

D. Risiko og sikkerhetsnett (skrevet som tekst)
Den første risikoen er læringstap: at studentene trener mindre på grunnferdigheter fordi AI kan “fylle ut” for dem. Mottiltaket er bevisst progresjon og design. Vi skal ha en miks av AI-frie aktiviteter (for å sikre kjernekompetanse) og AI-assisterte aktiviteter (for å lære profesjonell arbeidsflyt), men alltid med krav om begrunnelse og etterprøvbarhet. Studentene skal erfare at AI ikke reduserer kravene – den flytter dem.
Den andre risikoen er feil, bias og falsk trygghet. AI kan presentere svake argumenter som sterke, eller generalisere der faget krever presisjon. Mottiltaket er å gjøre verifikasjon til vurdert kompetanse og å trene på “feilsøkingskultur”: Studentene må lære å spørre “hva kan være galt her?”, “hva mangler?”, “hva ville endret konklusjonen?”. I profesjonsfag blir dette like grunnleggende som å lære prosedyrer.
Den tredje risikoen er personvern- og etikkglidning. Når verktøy er lett tilgjengelige, er fristelsen stor til å lime inn pasienthistorier, elevdata eller klientinformasjon for å få “bedre svar”. Mottiltaket er institusjonsgodkjente verktøy, tydelige røde linjer, og praktisk trening i anonymisering, dataminimering og samtykke. I tillegg må det være tydelig ansvarsplassering: hvem eier risikoen, hvem godkjenner verktøyene, og hva er konsekvensen ved brudd?
Den fjerde risikoen er ulikhet. Hvis tilgang, opplæring og kultur varierer mellom institusjoner og emner, blir AI et nytt klasseskille. Mottiltaket er nasjonal minimumsstandard (AI-førerkort), institusjonslisenser og finansiering som sikrer at alle har et likt startpunkt.
Den femte risikoen er overvåkning og automatisert rangering. AI kan brukes til å overvåke studenter, predikere prestasjon eller foreslå “sortering”. Det svekker tillit og kan slå urettferdig ut. Mottiltaket er klare begrensninger: ingen automatisert vedtaksmyndighet i vurdering, krav om menneskelig ansvar og transparens, og obligatorisk risikovurdering før innføring.
Den sjette risikoen er uklarhet om fusk som skaper urettferdighet og konflikter. Når reglene er uklare, blir det tilfeldig hvem som blir tatt og hvem som blir belønnet. Mottiltaket er trafikklysmodell, tydelige emnebeskrivelser, og vurderingsformer der studentens forståelse må fram gjennom forsvar, endring og refleksjon – ikke bare gjennom et sluttprodukt.

E. Måling og ansvarliggjøring (KPI-er i tekst)
Vi skal måle om politikken fungerer ved å kombinere læringsdata, integritet og tillit. Først må vi følge andelen emner som faktisk har tydelig KI-policy, og om studentene opplever reglene som forståelige og rettferdige. Deretter må vi måle studentenes verifikasjonskompetanse, ikke ved selvrapportering, men ved rubrikker som vurderer kvaliteten på AI-logg, dokumentert kildebruk og evnen til å peke på svakheter i egne løsninger. Vi må også følge utviklingen i fuskesaker knyttet til AI, og skille mellom saker som handler om reell uredelighet og saker som skyldes uklare regler. I tillegg bør vi måle gjennomføring og stryk/frafall i emner som innfører AI-lab/klinikk, for å se om tiltakene gir mer mestring. Til slutt må vi følge tillit: hvordan sensorer, praksisfelt og studenter vurderer rettferdigheten i vurderingssystemet og om gradsverdien oppleves som robust.

F. One-liner (maks 20 ord)
AI i utdanning skal gi dypere læring – ikke bare raskere tekst.

G. Vanskeligste motargument + vårt beste svar (utdypet som tekst)
Motargument (steelman): “Kjernen i en grad er at den beviser individuell kompetanse. Når AI normaliseres, kan vi ikke vite hva studenten faktisk kan. Studentene lærer å outsource tenkning, og graden mister verdi i arbeidslivet. Dessuten vil noen studenter bli mye bedre til å ‘spille systemet’ enn andre, og da blir vurdering urettferdig.”
Vårt beste svar: Dette motargumentet treffer et helt legitimt krav: samfunnet må kunne stole på at en kandidat faktisk kan faget. Men konklusjonen blir feil fordi den antar at vurdering alltid må være en vurdering av sluttproduktet alene. Graden mister ikke verdi av at AI finnes; den mister verdi hvis vi fortsetter å vurdere på en måte som AI lett kan etterligne. Derfor er Teknologisk folkepartis løsning å flytte vurderingens tyngdepunkt fra “leveranse” til “kompetanse i prosess”.
Når AI er tillatt, men bruken må være sporbar (AI-logg), etterprøvbar (verifikasjon) og forsvares (muntlig/praktisk kontroll), blir det faktisk vanskeligere å skjule manglende forståelse. En student kan kanskje få AI til å skrive en overbevisende rapport, men vil avsløres når hun må forklare hvorfor en metode er valgt, hvilke antakelser som ligger inne, hva som er usikkert, hva som ville endre konklusjonen, og hvordan løsningen oppfører seg når forutsetninger endres. Dette er nettopp profesjonskompetanse: å kunne stå ansvarlig for egne vurderinger.
Dessuten løser vår modell rettferdighetsproblemet bedre enn forbud. Forbud gir ujevn håndheving og skjult bruk – altså mer urettferdighet. Åpen, regulert bruk med klare rammer gir likere konkurransevilkår, fordi alle vet hva som er lov, og alle må gjennom de samme kontrollpunktene. Vi gjør med andre ord graden mer robust: Den blir ikke et bevis på “hvem som kan produsere tekst”, men et bevis på hvem som kan tenke, verifisere, begrunne og ta ansvar i en virkelighet der AI er til stede. Det er akkurat den typen kompetanse arbeidslivet etterspør – og som demokratiet trenger for å holde teknologien ansvarlig.

