\subsection{Pipeline Flow Diagram}

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance = 1.8cm, auto]
    \node [cloud] (user) {User};
    \node [block, below of=user] (input) {Text or Speech};
    \node [decision, below of=input] (default) {Default?};
    \node [block, left of=default, node distance=3.2cm] (defaultResp) {Read pre-generated\\audio/JSON};
    \node [block, below of=default, node distance=2.2cm] (openai) {OpenAI chain\\(LLM + parser)};
    \node [block, below of=openai] (tts) {ElevenLabs TTS\\(parallel per message)};
    \node [block, below of=tts] (phonemes) {ffmpeg + Rhubarb\\(parallel per message)};
    \node [block, below of=phonemes] (response) {Base64 + JSON\\response};
    \node [cloud, below of=response] (client) {Frontend};

    \path [line] (user) -- (input);
    \path [line] (input) -- (default);
    \path [line] (default) -- node {Yes} (defaultResp);
    \path [line] (default) -- node {No} (openai);
    \path [line] (openai) -- (tts);
    \path [line] (tts) -- (phonemes);
    \path [line] (phonemes) -- (response);
    \path [line] (response) -- (client);
    \path [line, dashed] (defaultResp) |- (client);
\end{tikzpicture}
\caption[Pipeline flow]{End-to-end pipeline: user input, default check, OpenAI chain, TTS, phonemes, response.}
\label{fig:pipeline}
\end{figure}

\subsection{Key Files}

\begin{itemize}
    \item \texttt{server.js}: Routes \texttt{/tts}, \texttt{/sts}, \texttt{/voices}; orchestrates default check, OpenAI, lip-sync.
    \item \texttt{modules/openAI.mjs}: LangChain chain, party program loading, structured output (text, facialExpression, animation).
    \item \texttt{modules/lip-sync.mjs}: Parallel TTS then parallel phonemes + base64/JSON attachment.
    \item \texttt{modules/elevenLabs.mjs}: ElevenLabs TTS.
    \item \texttt{modules/rhubarbLipSync.mjs}: ffmpeg MP3$\to$WAV, Rhubarb phonemes \textcite{rhubarb_lipsync}.
    \item \texttt{modules/whisper.mjs}: WebM$\to$MP3, OpenAI Whisper transcription.
\end{itemize}
